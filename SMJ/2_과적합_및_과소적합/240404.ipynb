{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과소적합(underfitting)\n",
    "- 모델이 너무 단순하거나, 규제가 너무 많거나, 충분한 훈련을 하지 않은 경우 발생\n",
    "- 네트워크가 훈련 세트에서 적절한 패턴을 학습하지 못했다는 의미\n",
    "- 그러나 너무 오래 훈련하면 모델이 과대적합(overfitting)되어 테스트 데이터에 일반화되지 않는 훈련 데이터로부터 패턴을 학습하게 된다.\n",
    "\n",
    "1. 적절한 epoch 수로 훈련\n",
    "2. 완전한 훈련 데이터 사용: 모델이 처리할 것으로 예상되는 전체 입력 범위를 포괄하는 것이 좋다.\n",
    "3. 정규화: 모델이 저장할 수 있는 정보의 양과 유형에 제약을 가하여, 적은 수의 패턴만 기억하게 만들어 일반화 가능성이 더 높은 패턴을 중점으로 최적화하게 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting git+https://github.com/tensorflow/docs\n",
      "  Cloning https://github.com/tensorflow/docs to c:\\users\\서민지\\appdata\\local\\temp\\pip-req-build-fcgco9fj\n",
      "  Resolved https://github.com/tensorflow/docs to commit ec3a1b3f9a604c6cd26c7537f2b9fd270a3eedbf\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting astor (from tensorflow-docs==2024.3.27.3713)\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\서민지\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-docs==2024.3.27.3713) (1.4.0)\n",
      "Collecting jinja2 (from tensorflow-docs==2024.3.27.3713)\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting nbformat (from tensorflow-docs==2024.3.27.3713)\n",
      "  Downloading nbformat-5.10.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: protobuf>=3.12 in c:\\users\\서민지\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-docs==2024.3.27.3713) (3.20.3)\n",
      "Collecting pyyaml (from tensorflow-docs==2024.3.27.3713)\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\서민지\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->tensorflow-docs==2024.3.27.3713) (2.1.5)\n",
      "Collecting fastjsonschema (from nbformat->tensorflow-docs==2024.3.27.3713)\n",
      "  Downloading fastjsonschema-2.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat->tensorflow-docs==2024.3.27.3713)\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\서민지\\appdata\\roaming\\python\\python311\\site-packages (from nbformat->tensorflow-docs==2024.3.27.3713) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\서민지\\appdata\\roaming\\python\\python311\\site-packages (from nbformat->tensorflow-docs==2024.3.27.3713) (5.14.2)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.3.27.3713)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.3.27.3713)\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.3.27.3713)\n",
      "  Downloading referencing-0.34.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat->tensorflow-docs==2024.3.27.3713)\n",
      "  Downloading rpds_py-0.18.0-cp311-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\서민지\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core->nbformat->tensorflow-docs==2024.3.27.3713) (4.2.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\서민지\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core->nbformat->tensorflow-docs==2024.3.27.3713) (306)\n",
      "Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.2 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 81.9/133.2 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 133.2/133.2 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading nbformat-5.10.3-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.4/78.4 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "   ---------------------------------------- 0.0/144.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 144.7/144.7 kB ? eta 0:00:00\n",
      "Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.5/85.5 kB ? eta 0:00:00\n",
      "Downloading fastjsonschema-2.19.1-py3-none-any.whl (23 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.8/60.8 kB ? eta 0:00:00\n",
      "Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.34.0-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.18.0-cp311-none-win_amd64.whl (206 kB)\n",
      "   ---------------------------------------- 0.0/206.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 206.7/206.7 kB 13.1 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: tensorflow-docs\n",
      "  Building wheel for tensorflow-docs (setup.py): started\n",
      "  Building wheel for tensorflow-docs (setup.py): finished with status 'done'\n",
      "  Created wheel for tensorflow-docs: filename=tensorflow_docs-2024.3.27.3713-py3-none-any.whl size=183877 sha256=9790f560941b852b726ee4d5a7de94fa4289fb471588f78ea45b5f54a09a1c8e\n",
      "  Stored in directory: C:\\Users\\서민지\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-yjqg4eug\\wheels\\34\\53\\89\\3db54cf97ce0f0261aaab3fdc12a847ea0879d34edf373e2c5\n",
      "Successfully built tensorflow-docs\n",
      "Installing collected packages: fastjsonschema, rpds-py, pyyaml, jinja2, attrs, astor, referencing, jsonschema-specifications, jsonschema, nbformat, tensorflow-docs\n",
      "Successfully installed astor-0.8.1 attrs-23.2.0 fastjsonschema-2.19.1 jinja2-3.1.3 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 nbformat-5.10.3 pyyaml-6.0.1 referencing-0.34.0 rpds-py-0.18.0 tensorflow-docs-2024.3.27.3713\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs 'C:\\Users\\서민지\\AppData\\Local\\Temp\\pip-req-build-fcgco9fj'\n",
      "  WARNING: The script jsonschema.exe is installed in 'c:\\Users\\서민지\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script jupyter-trust.exe is installed in 'c:\\Users\\서민지\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/tensorflow/docs\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://mlphysics.ics.uci.edu/data/higgs/HIGGS.csv.gz\n",
      "\u001b[1m  23199744/2816407858\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29:34:55\u001b[0m 38us/step"
     ]
    }
   ],
   "source": [
    "# 힉스(Higgs) 데이터세트, 28개의 특성과, 이진 클래스 레이블이 있는 11,000,000개\n",
    "\n",
    "gz = tf.keras.utils.get_file('HIGGS.csv.gz', 'http://mlphysics.ics.uci.edu/data/higgs/HIGGS.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "힉스 데이터 세트\n",
    "- 28개의 특성(Features)\n",
    "- 이진 클래스 레이블(Binary Class Labels): 데이터 포인트에 대한 목표 변수\n",
    "- 데이터 구조: 11,000,000 x 28 크기의 행렬 (데이터 포인트 x 특성)\n",
    "- 대규모 데이터셋의 경우 전처리 과정이 필요할 수있다.\n",
    "    - 데이터의 결측치 처리\n",
    "    - 이상치 제거\n",
    "    - 특성 스케일링\n",
    "    - 범주형 변수의 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.experimental.CsvDataset(gz,[float(),]*(FEATURES+1), compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_row(*row):\n",
    "  label = row[0]\n",
    "  features = tf.stack(row[1:],1)\n",
    "  return features, label  # feature_vector, label 쌍으로 다시 압축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대규모 데이터 배치에서 작업\n",
    "packed_ds = ds.batch(10000).map(pack_row).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features,label in packed_ds.batch(1000).take(1):\n",
    "  print(features[0])\n",
    "  plt.hist(features.numpy().flatten(), bins = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_VALIDATION = int(1e3) # 1000\n",
    "N_TRAIN = int(1e4)      # 10000\n",
    "BUFFER_SIZE = int(1e4)  # 데이터셋을 셔플링할 때 사용되는 버퍼의 크기\n",
    "BATCH_SIZE = 500\n",
    "STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_ds = packed_ds.take(N_VALIDATION).cache()\n",
    "# 로더가 각 epoch 에서 파일 데이터를 다시 로딩할 필요 없도록 캐싱\n",
    "train_ds = packed_ds.skip(N_VALIDATION).take(N_TRAIN).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
