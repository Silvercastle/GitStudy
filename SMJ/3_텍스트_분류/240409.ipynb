{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Language Processing with Disaster Tweets\n",
    "https://www.kaggle.com/c/nlp-getting-started/overview\n",
    "\n",
    "텍스트 분석\n",
    "- 데이터 로드\n",
    "- 데이터 전처리 (스탑워드 등)\n",
    "- 토큰화 (단어를 index로)\n",
    "- 패딩 (토큰화한 리스트의 길이를 동일하게)\n",
    "- 임베딩\n",
    "- 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data\\sample_submission.csv\n",
      ".\\data\\test.csv\n",
      ".\\data\\train.csv\n"
     ]
    }
   ],
   "source": [
    "# %pip install pandas\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd # 데이터 처리, CSV 파일 입출력\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('.\\\\data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\서민지\\Desktop\\ML\\HDAT\\HDAT\\SMJ\\3_텍스트_분류\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('.\\data\\\\train.csv')\n",
    "test = pd.read_csv('.\\data\\\\test.csv')\n",
    "submission = pd.read_csv('.\\data\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 5), (3263, 4), (3263, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "7608    1\n",
       "7609    1\n",
       "7610    1\n",
       "7611    1\n",
       "7612    1\n",
       "Name: target, Length: 7613, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train.target\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Our Deeds are the Reason of this #earthquake M...\n",
       "1                  Forest fire near La Ronge Sask. Canada\n",
       "2       All residents asked to 'shelter in place' are ...\n",
       "3       13,000 people receive #wildfires evacuation or...\n",
       "4       Just got sent this photo from Ruby #Alaska as ...\n",
       "                              ...                        \n",
       "7608    Two giant cranes holding a bridge collapse int...\n",
       "7609    @aria_ahrary @TheTawniest The out of control w...\n",
       "7610    M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...\n",
       "7611    Police investigating after an e-bike collided ...\n",
       "7612    The Latest: More Homes Razed by Northern Calif...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = train.text\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\서민지\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\서민지\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\서민지\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\서민지\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\서민지\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\서민지\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\서민지\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you',\n",
       "       \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself',\n",
       "       'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her',\n",
       "       'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them',\n",
       "       'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom',\n",
       "       'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are',\n",
       "       'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
       "       'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and',\n",
       "       'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\n",
       "       'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
       "       'through', 'during', 'before', 'after', 'above', 'below', 'to',\n",
       "       'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under',\n",
       "       'again', 'further', 'then', 'once', 'here', 'there', 'when',\n",
       "       'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
       "       'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n",
       "       'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will',\n",
       "       'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll',\n",
       "       'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn',\n",
       "       \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\",\n",
       "       'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma',\n",
       "       'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\",\n",
       "       'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\",\n",
       "       'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Stopwords, 불용어 제거\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "np.array(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteStopwords(text):\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our Deeds are the Reason of this #earthquake M...\n",
       "1               Forest fire near La Ronge Sask. Canada\n",
       "2    All residents asked to 'shelter in place' are ...\n",
       "3    13,000 people receive #wildfires evacuation or...\n",
       "4    Just got sent this photo from Ruby #Alaska as ...\n",
       "5    #RockyFire Update => California Hwy. 20 closed...\n",
       "6    #flood #disaster Heavy rain causes flash flood...\n",
       "7    I'm on top of the hill and I can see a fire in...\n",
       "8    There's an emergency evacuation happening now ...\n",
       "9    I'm afraid that the tornado is coming to our a...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        deeds reason #earthquake may allah forgive us\n",
       "1               forest fire near la ronge sask. canada\n",
       "2    residents asked 'shelter place' notified offic...\n",
       "3    13,000 people receive #wildfires evacuation or...\n",
       "4    got sent photo ruby #alaska smoke #wildfires p...\n",
       "5    #rockyfire update => california hwy. 20 closed...\n",
       "6    #flood #disaster heavy rain causes flash flood...\n",
       "7                       i'm top hill see fire woods...\n",
       "8    there's emergency evacuation happening buildin...\n",
       "9                    i'm afraid tornado coming area...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sentences.apply(deleteStopwords)\n",
    "sentences.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.1.post1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\서민지\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.0-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.6 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.6 kB ? eta -:--:--\n",
      "     ------------------------- ------------ 41.0/60.6 kB 653.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.6/60.6 kB 799.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\서민지\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.4.1.post1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.6 MB 8.6 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.8/10.6 MB 10.0 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.4/10.6 MB 9.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.0/10.6 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.7/10.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.2/10.6 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.7/10.6 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.3/10.6 MB 11.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.8/10.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.2/10.6 MB 11.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.7/10.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.9/10.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.5/10.6 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.2/10.6 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.7/10.6 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.1/10.6 MB 11.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.5/10.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.9/10.6 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.4/10.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading scipy-1.13.0-cp311-cp311-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/46.2 MB 9.6 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.7/46.2 MB 8.9 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 1.3/46.2 MB 8.9 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 1.7/46.2 MB 9.2 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 2.2/46.2 MB 10.1 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.8/46.2 MB 10.5 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 3.3/46.2 MB 10.4 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.7/46.2 MB 10.3 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 4.2/46.2 MB 10.2 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 4.4/46.2 MB 9.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.8/46.2 MB 9.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 5.3/46.2 MB 9.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 5.8/46.2 MB 9.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.3/46.2 MB 9.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.0/46.2 MB 10.2 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.5/46.2 MB 10.2 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.1/46.2 MB 10.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.6/46.2 MB 10.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 9.2/46.2 MB 10.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 9.8/46.2 MB 10.7 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 10.3/46.2 MB 10.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.9/46.2 MB 10.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 11.4/46.2 MB 10.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 11.9/46.2 MB 10.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 12.5/46.2 MB 11.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 13.1/46.2 MB 11.1 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 13.6/46.2 MB 11.1 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 14.3/46.2 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 14.8/46.2 MB 11.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 15.3/46.2 MB 11.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 15.7/46.2 MB 11.9 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 16.2/46.2 MB 11.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 16.8/46.2 MB 11.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 17.3/46.2 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.8/46.2 MB 11.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 18.3/46.2 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.7/46.2 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 19.4/46.2 MB 11.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.9/46.2 MB 11.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 20.4/46.2 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 20.8/46.2 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 21.4/46.2 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.0/46.2 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 22.7/46.2 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 23.1/46.2 MB 11.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 23.8/46.2 MB 11.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 24.2/46.2 MB 11.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 24.6/46.2 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 25.0/46.2 MB 10.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 25.3/46.2 MB 10.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 25.7/46.2 MB 10.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 26.2/46.2 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 26.7/46.2 MB 10.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 27.2/46.2 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 27.8/46.2 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.0/46.2 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.2/46.2 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.6/46.2 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.3/46.2 MB 10.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.7/46.2 MB 10.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 30.1/46.2 MB 9.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 30.6/46.2 MB 9.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 31.2/46.2 MB 10.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 31.7/46.2 MB 9.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 32.0/46.2 MB 9.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 32.6/46.2 MB 9.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 33.2/46.2 MB 9.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.7/46.2 MB 9.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 34.2/46.2 MB 9.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 34.6/46.2 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 35.0/46.2 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 35.5/46.2 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 35.6/46.2 MB 9.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 35.8/46.2 MB 9.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 36.1/46.2 MB 9.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 36.4/46.2 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 36.8/46.2 MB 9.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 37.2/46.2 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 37.6/46.2 MB 8.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 38.0/46.2 MB 8.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.5/46.2 MB 9.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 39.2/46.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.7/46.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 40.2/46.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.7/46.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 41.3/46.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.8/46.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 42.3/46.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 42.7/46.2 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.3/46.2 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.9/46.2 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.5/46.2 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 45.0/46.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.5/46.2 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.1/46.2 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 8.4 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.4.1.post1 scipy-1.13.0 threadpoolctl-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Train, Validation 나누기\n",
    "\n",
    "# %pip install scikit-learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(sentences,\n",
    "                                                                labels, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6090,), (1523,), (6090,), (1523,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences.shape, val_sentences.shape, train_labels.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화\n",
    "vocab_size = 1000\n",
    "token = Tokenizer(num_words=vocab_size)\n",
    "token.fit_on_texts(sentences) # sentences 데이터 기준으로 빈번한 1000개의 단어 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6477               still sunk i've actually met idol ????\n",
      "2524    times desolation trouble daniel's persistent p...\n",
      "439        @casper_rmg @bestcomedyvine whats cracking cuz\n",
      "1824                    @olliebailey11 havnt crashed ? ??\n",
      "4386    remove http://t.co/7ieiz619h0 linkury browser ...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24, 373, 267, 557], [178, 398, 447, 388, 133, 3, 1, 2], [], [330], [3, 1, 2, 451, 3, 1, 2, 3, 1, 2]]\n"
     ]
    }
   ],
   "source": [
    "train_sequences = token.texts_to_sequences(train_sentences)\n",
    "val_sequences = token.texts_to_sequences(val_sentences)\n",
    "print(train_sequences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩\n",
    "\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "max_length = 120\n",
    "train_pad = pad_sequences(train_sequences, truncating=trunc_type, padding=padding_type, maxlen=max_length)\n",
    "val_pad = pad_sequences(val_sequences, truncating=trunc_type, padding=padding_type, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델\n",
    "\n",
    "train_labels = np.asarray(train_labels)\n",
    "val_labels = np.asarray(val_labels)\n",
    "\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "input_shape = train_pad.shape\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(1000, embedding_dim),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape)    # unbuilt 이슈.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6090</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">64,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_18                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6090</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_19                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6090</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6090</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6090</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">6090</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_12 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;34m6090\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m64,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_18                │ (\u001b[38;5;34m6090\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_19                │ (\u001b[38;5;34m6090\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m41,216\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m6090\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m6090\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m6090\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,489</span> (685.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m175,489\u001b[0m (685.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,489</span> (685.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m175,489\u001b[0m (685.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "191/191 - 23s - 119ms/step - accuracy: 0.7122 - loss: 0.5572 - val_accuracy: 0.7978 - val_loss: 0.4514\n",
      "Epoch 2/3\n",
      "191/191 - 14s - 75ms/step - accuracy: 0.8174 - loss: 0.4229 - val_accuracy: 0.8089 - val_loss: 0.4413\n",
      "Epoch 3/3\n",
      "191/191 - 14s - 72ms/step - accuracy: 0.8300 - loss: 0.3925 - val_accuracy: 0.8017 - val_loss: 0.4540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25b45724d10>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pad, train_labels, validation_data=(val_pad, val_labels),\n",
    "          epochs=3,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 전처리 및 예측\n",
    "\n",
    "test_sequences = test.text\n",
    "test_sequences = test_sequences.apply(deleteStopwords)\n",
    "test_sequences = token.texts_to_sequences(test_sequences)\n",
    "test_pad = pad_sequences(test_sequences, truncating=trunc_type, padding=padding_type, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       0\n",
       "4  11       1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_file = pd.DataFrame()\n",
    "sub_file['id'] = test['id']\n",
    "sub_file['target'] = y_pred.round().astype(int)\n",
    "sub_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_file.to_csv('.\\data\\submission_lstm.csv', index=False)\n",
    "\n",
    "# score: 0.77995 (dropout(0.5))\n",
    "# score: 0.77719 (dropout(0.4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
